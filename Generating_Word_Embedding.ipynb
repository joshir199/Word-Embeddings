{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eonurErOYoFU"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "from datetime import datetime\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Embedding, GlobalAveragePooling1D\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.version.VERSION)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFT-jlcrZynm",
        "outputId": "10367f34-1f7f-4066-8d12-6a45583b4d9a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "\n",
        "dataset = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", url, untar=True, cache_dir='.', cache_subdir='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOOYxfy4Z7Mk",
        "outputId": "5b87a29c-6135-4b2b-a7fa-0b27c533766b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84125825/84125825 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.path.dirname(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw1SFFg3JrPm",
        "outputId": "061698b6-7253-4325-efb8-88063c0fc50b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')\n",
        "os.listdir(dataset_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNa54esDafvu",
        "outputId": "279711ad-cc26-41ea-bb7a-8f4940bbb5ec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['imdbEr.txt', 'train', 'imdb.vocab', 'README', 'test']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = os.path.join(dataset_dir, 'train')\n",
        "os.listdir(train_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YYLlQv4bC7E",
        "outputId": "2e09ae04-b771-4de8-9a52-5e979d55e553"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neg',\n",
              " 'urls_neg.txt',\n",
              " 'pos',\n",
              " 'urls_pos.txt',\n",
              " 'urls_unsup.txt',\n",
              " 'labeledBow.feat',\n",
              " 'unsupBow.feat',\n",
              " 'unsup']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remove_dir = os.path.join(train_set, 'unsup')\n",
        "shutil.rmtree(remove_dir)"
      ],
      "metadata": {
        "id": "oa9WnWbtKjJx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(train_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OG6SoQ5gKqTO",
        "outputId": "640ca7a0-1394-4c49-8c99-c1b309f1a2d0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['neg',\n",
              " 'urls_neg.txt',\n",
              " 'pos',\n",
              " 'urls_pos.txt',\n",
              " 'urls_unsup.txt',\n",
              " 'labeledBow.feat',\n",
              " 'unsupBow.feat']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1024\n",
        "seed = 1234\n",
        "train_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train', batch_size=batch_size, validation_split=0.2,\n",
        "    subset='training', seed=seed)\n",
        "val_ds = tf.keras.preprocessing.text_dataset_from_directory(\n",
        "    'aclImdb/train', batch_size=batch_size, validation_split=0.2,\n",
        "    subset='validation', seed=seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fj_95Y3KK9X7",
        "outputId": "c7974089-3093-43e5-8ba3-8be2b867d44a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for text_batch, label_batch in train_ds.take(1):\n",
        "  print(text_batch.shape)\n",
        "  print(label_batch.shape)\n",
        "  for i in range(2):\n",
        "    print(label_batch[i].numpy(), text_batch.numpy()[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gGWyJaSLq-G",
        "outputId": "51de1d0b-fcb3-4e88-c522-22734c7e8a69"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1024,)\n",
            "(1024,)\n",
            "0 b'This movie was extremely poorly conceived from every angle except technological. I stood and watched everyone waddle out of the theater, their faces drained like their lives flashed before their eyes -- eyes wandering at their neighbor, wondering if it was just them. I mean, how could the movie really be bad. Nobody\\'ll admit it, it\\'s a classic case of The Emperor Wears No Clothes. \"Who am I to question a movie containing a guy who stops a jet liner?\" But the fact remains, every member of the audience is thinking what I\\'m writing right now. I actually plagiarized their faces.<br /><br />Obviously Lois is only aroused by power, she won\\'t even have a cup of coffee with the Superman With Glasses who doesn\\'t stop jet liners. It can\\'t be the look in \"his\" eyes to the depths of his soul or anything like that. In the old Supermans, she had some level of connection with him, he wasn\\'t priority number 1, obviously, but it strengthened her character that she was \"torn\". I bet Henry Kissinger would have even won this Lois over before Clark Kent.<br /><br />And now it\\'s official, Kryptonite does to Superman what eating at McDonalds does to the avg. person.<br /><br />SUPERMAN \"ONE\" He loses his earth dad, then finds his real super dad, the story is captivating every step of the way. He\\'s human, he relates to people and he feels love for people, he relates to highschool students, he relates to people who feel different. He relates. The Superman Returns superman seems to relate only to Superpeople and it seems he\\'s just \"doing a job\" when he\\'s saving people.<br /><br />There\\'s something about Clark that Lois likes, she\\'s really internally in love with him but can\\'t admit it, and when he comes into the picture as Superman, it throws a kink in the on-the-rocks love. Without Superman, she would\\'ve fallen in love with Clark (at least that\\'s what the movie points to, whether it was the intention or not). Superman Returns is a love story between a woman and SUPERMAN, Clark is like a pile of horse maneur to Lois. Literally.<br /><br />SUPERMAN TWO I just watched it again. As a kid, I \"thought\" I enjoyed the action, but now I know it was the STORY that held me then too, watching it over and over again. If I saw Superman Returns as a child, I would\\'ve hated it then too, I think.<br /><br />There is so much heart and soul and superpower going around in this movie, it\\'s sick. Superman gives up his powers for love as a world plot is going on and meanwhile, MEANWHILE, Lex Luther\\'s got something fantastic up his sleeve.<br /><br />SUPERMAN THREE Now there\\'s a three-way love story between Superman and Lana and Clark, only humanity wins and Clark\\'s inner nature beats Superman\\'s power, because when his SUPERmoral nature is gone and he\\'s SuperHUMAN (who does human things with his superpowers), she sees it\\'s not the power of Superman that she\\'s in love with, it\\'s not SUPERpowerman, but SUPERMORTALman that she loves -- and who\\'s really SUPER. And when she tells Clark she \"prefers\" him to Superman, he is elated, he has made a human connection again. He wants to be accepted for who he is, not just for his ability to bend steel. THIS IS THE KIND OF STUFF THAT\\'S MISSING FROM SUPERMAN RETURNS.<br /><br />Clark super-sneezes to help the kid get a strike - humanity again. Plus, it\\'s an INERESTING use of superpowers. He\\'s not just using straight brute strength.<br /><br />He crushes the coal into a diamond for his woman because she had to sell hers, love is the only thing that drives him to use his powers other than for saving.<br /><br />It seems there\\'s nothing at stake in Superman Returns. Even in Superman Three, we see the damages caused by the nemesis\\' world domination plot.. we see suffering, we see how it effects Pryor and others and people in the middle of it.. there\\'s no damage, esp. emotional from Lex\\'s plot to sink the US. We see a glob of crystal thrown into space.. Superman had to get very creative in the first three Supermans in order to stop the plot against him, he couldn\\'t just \"access\" his superpowers. In the first one, he had to stop two missiles going in different directions and then break his universal mandate and erase history to save Lois\\' life... (this was THIRTY YEARS AGO!!\") In the second one, he had to outsmart three guys that he was already more POWERFUL than, but combined with Lex\\'s genius, and the villains\\' immoral tactics, Superman\\'s overpowering wasn\\'t enough, he had to work one against the other and outsmart them... In Superman III, again, his superpowers weren\\'t enough to win.. He had to outsmart a computer that calculated everything it saw. He couldn\\'t use straight aggression on the computer because it calculated it in advance, so he had to use a benign acid that would only become deadly to the computer after the computer responded to the aggression. And he found that acid earlier when he couldn\\'t simply use his superpowers to BLOW out a fire because it was a chemical fire, so he had to use his superbrains -- he couldn\\'t carry water, so he froze a lake and dropped it on the fire.. Now in Superman Returns, he simply lunges the island into outerspace, like a night temp for UPS. He doesn\\'t need to figure anything out, he just uses his \"super strength\". And Lex Luther\\'s brilliance was shown at the premeditation level of a junkie who just ran out of junk.<br /><br />To say nothing of the fact that he threw that island into outerspace after getting stabbed with a KNIFE of kyrptonite right in the bloodstream AND the island itself was dripping kryptonite spores in his face, but he just averted his eyes and nose like it wasn\\'t Grey Poupon he was looking at.'\n",
            "1 b\"I don't think most people give this movie as much credit as it deserves. I love low budget horror movies and this takes the cake, especially for originality. Yes the Scarecrow is a Kung-Fu fighting frightner, but why not? No one else is willing to go that far. I really haven't had this much fun watching a movie since Candyman. So the town picks on this one kid calling him scarecrow, even his mom doesn't care about him. Then he gets killed and the spirit is infused with in the Scarecrow, who then goes on a Killing spree. His demise is relatively easy to assume once the movie gets going. The dedications at the end go straight to a bunch of horror directors, but with most dedication towards Dario Argento really struck me as cool, these folks who wanna make movies of a newer genre. Over the movie has a lot of Arnold rip offs, with one liners you'll definitely laugh at like stick around and he kills the sheriff with a stick. I would say, grab a pizza some friends an laugh your A$$ off with this movie. I love it for its originality, most fun.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "0oGV0uUINI0L"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = tf.keras.layers.Embedding(1000, 5)"
      ],
      "metadata": {
        "id": "OTtDs2Y2NzQh"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = tf.constant([1,1,3])\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRpVSO7lOHdv",
        "outputId": "cd6337a6-7700-42e0-ed16-0f380481807a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 1, 3], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer.input_dim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6crRBFcQOz_Q",
        "outputId": "98ebcb73-cc4c-4706-bd5a-57fb07b22ed3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = embedding_layer(res)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoqPOzLcP3uT",
        "outputId": "8b2378c6-a131-4b21-b2e2-a2c4e990bf2c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
              "array([[-0.04154678, -0.04529047,  0.00974279,  0.00978858,  0.04587581],\n",
              "       [-0.04154678, -0.04529047,  0.00974279,  0.00978858,  0.04587581],\n",
              "       [-0.00075334, -0.03950322, -0.00839678, -0.0259989 ,  0.02940358]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res2  = tf.constant([1,1,2])\n",
        "result2 = embedding_layer(res2)\n",
        "result2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbVPIoULQfHJ",
        "outputId": "9bbf8155-8d3d-49dc-950d-f7c54b71b549"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
              "array([[-0.04154678, -0.04529047,  0.00974279,  0.00978858,  0.04587581],\n",
              "       [-0.04154678, -0.04529047,  0.00974279,  0.00978858,  0.04587581],\n",
              "       [ 0.04009653,  0.03935075, -0.01837511,  0.02238211,  0.01861404]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result3 = embedding_layer(tf.constant([[0,1,2],[3,4,5]]))\n",
        "result3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXWdn9BPRHuA",
        "outputId": "68e61969-9bd9-42ec-a3d6-10a8a8213420"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation), '')"
      ],
      "metadata": {
        "id": "RUZVxAytSb8Q"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vocabulary size and number of words in a sequence.\n",
        "vocab_size = 10000\n",
        "sequence_length = 100\n",
        "\n",
        "# Use the text vectorization layer to normalize, split, and map strings to\n",
        "# integers. Note that the layer uses the custom standardization defined above.\n",
        "# Set maximum_sequence length as all samples are not of the same length.\n",
        "# Also, called Tokenisation\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length)\n",
        "\n",
        "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
        "text_ds = train_ds.map(lambda x, y: x)\n",
        "vectorize_layer.adapt(text_ds)"
      ],
      "metadata": {
        "id": "c455bviuSfz_"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.attention.multi_head_attention import activation\n",
        "embedding_dim=16\n",
        "\n",
        "model = Sequential()\n",
        "model.add(vectorize_layer)\n",
        "model.add(Embedding(vocab_size, embedding_dim))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dense(16, activation = 'relu'))\n",
        "model.add(Dense(1))"
      ],
      "metadata": {
        "id": "myvtilkqT1rI"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
      ],
      "metadata": {
        "id": "4NYrV1P7VPhu"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "SKDgN1vzVSF8"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=10,\n",
        "    callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cM69_6MVV7Y",
        "outputId": "cfbfa6fe-8b8c-40a4-dfa5-b0726f2f7054"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "20/20 [==============================] - 2s 82ms/step - loss: 0.6920 - accuracy: 0.4997 - val_loss: 0.6899 - val_accuracy: 0.5010\n",
            "Epoch 2/10\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 0.6867 - accuracy: 0.4997 - val_loss: 0.6834 - val_accuracy: 0.5010\n",
            "Epoch 3/10\n",
            "20/20 [==============================] - 1s 49ms/step - loss: 0.6778 - accuracy: 0.4997 - val_loss: 0.6732 - val_accuracy: 0.5010\n",
            "Epoch 4/10\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 0.6644 - accuracy: 0.4997 - val_loss: 0.6587 - val_accuracy: 0.5010\n",
            "Epoch 5/10\n",
            "20/20 [==============================] - 1s 55ms/step - loss: 0.6460 - accuracy: 0.5019 - val_loss: 0.6396 - val_accuracy: 0.5142\n",
            "Epoch 6/10\n",
            "20/20 [==============================] - 1s 49ms/step - loss: 0.6222 - accuracy: 0.5466 - val_loss: 0.6154 - val_accuracy: 0.5880\n",
            "Epoch 7/10\n",
            "20/20 [==============================] - 1s 49ms/step - loss: 0.5931 - accuracy: 0.6256 - val_loss: 0.5874 - val_accuracy: 0.6580\n",
            "Epoch 8/10\n",
            "20/20 [==============================] - 1s 57ms/step - loss: 0.5604 - accuracy: 0.6923 - val_loss: 0.5576 - val_accuracy: 0.7064\n",
            "Epoch 9/10\n",
            "20/20 [==============================] - 1s 50ms/step - loss: 0.5262 - accuracy: 0.7386 - val_loss: 0.5284 - val_accuracy: 0.7412\n",
            "Epoch 10/10\n",
            "20/20 [==============================] - 1s 56ms/step - loss: 0.4929 - accuracy: 0.7702 - val_loss: 0.5016 - val_accuracy: 0.7598\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x79a5bac3b220>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUbm9ebXVkav",
        "outputId": "acce75d4-a18d-4ca1-8988-efc7f4ef5d36"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " text_vectorization (TextVec  (None, 100)              0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 100, 16)           160000    \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 16)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                272       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160,289\n",
            "Trainable params: 160,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights = model.get_layer('embedding_1').get_weights()[0]\n",
        "vocab = vectorize_layer.get_vocabulary()"
      ],
      "metadata": {
        "id": "HRhsMdDXWclf"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(vocab):\n",
        "  if  index == 0: continue # skip 0, it's padding.\n",
        "  vec = weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "metadata": {
        "id": "s0bJVvMCWomt"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('aclImdb/weights/vectors.tsv')\n",
        "  files.download('aclImdb/weights/metadata.tsv')\n",
        "except Exception as e:\n",
        "  pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "u9wri9FZXNxV",
        "outputId": "a7ae9ad2-69f9-41b5-b135-6a56d94e898c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b45817ee-c9d9-4698-8229-794b1a13dd3f\", \"vectors.tsv\", 1911665)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9231bbf5-c171-4f4c-8a8c-1740cb798a35\", \"metadata.tsv\", 76484)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}